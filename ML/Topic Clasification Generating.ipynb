{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fluid-preservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have TensorFlow version 2.9.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "\n",
    "# This code was tested with TensorFlow v1.4\n",
    "print(\"You have TensorFlow version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "supported-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backlist(text):\n",
    "    result = re.sub(r\"\\[|\\]|\\,|\\'\",'', text)\n",
    "    return result\n",
    "def tolist(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fifty-conservative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15740</th>\n",
       "      <td>15740</td>\n",
       "      <td>15740</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.8127</td>\n",
       "      <td>politik, ni, kuasa, tak, dah, nak, orang, kan,...</td>\n",
       "      <td>malaysia sibuk tukar politik negara luar terus...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15741</th>\n",
       "      <td>15741</td>\n",
       "      <td>15741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5758</td>\n",
       "      <td>politik, milik, bukan, seni, kerja, putus, mam...</td>\n",
       "      <td>makna isra miraj putus asa ada apa</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15742</th>\n",
       "      <td>15742</td>\n",
       "      <td>15742</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8921</td>\n",
       "      <td>politik, milik, bukan, seni, kerja, putus, mam...</td>\n",
       "      <td>prn bn mampu tahan rana amal politik matang</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15743</th>\n",
       "      <td>15743</td>\n",
       "      <td>15743</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.8666</td>\n",
       "      <td>politik, indonesia, cari, buat, kalau, jadi, b...</td>\n",
       "      <td>gak mungkin jago airlangga hartanto ahy cak pa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15744</th>\n",
       "      <td>15744</td>\n",
       "      <td>15744</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.9429</td>\n",
       "      <td>buat, kata, makin, tinggi, sbb, bagai, kes, of...</td>\n",
       "      <td>uni cancel buat majlis konvo kata sbb kes maki...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "15740       15740        15740            23.0              0.8127   \n",
       "15741       15741        15741             1.0              0.5758   \n",
       "15742       15742        15742             1.0              0.8921   \n",
       "15743       15743        15743            15.0              0.8666   \n",
       "15744       15744        15744            29.0              0.9429   \n",
       "\n",
       "                                                Keywords  \\\n",
       "15740  politik, ni, kuasa, tak, dah, nak, orang, kan,...   \n",
       "15741  politik, milik, bukan, seni, kerja, putus, mam...   \n",
       "15742  politik, milik, bukan, seni, kerja, putus, mam...   \n",
       "15743  politik, indonesia, cari, buat, kalau, jadi, b...   \n",
       "15744  buat, kata, makin, tinggi, sbb, bagai, kes, of...   \n",
       "\n",
       "                                                    Text   Emotion  \n",
       "15740  malaysia sibuk tukar politik negara luar terus...  negative  \n",
       "15741                 makna isra miraj putus asa ada apa  negative  \n",
       "15742        prn bn mampu tahan rana amal politik matang  negative  \n",
       "15743  gak mungkin jago airlangga hartanto ahy cak pa...  negative  \n",
       "15744  uni cancel buat majlis konvo kata sbb kes maki...  negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_data.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efficient-royal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15740</th>\n",
       "      <td>malaysia sibuk tukar politik negara luar terus...</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15741</th>\n",
       "      <td>makna isra miraj putus asa ada apa</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15742</th>\n",
       "      <td>prn bn mampu tahan rana amal politik matang</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15743</th>\n",
       "      <td>gak mungkin jago airlangga hartanto ahy cak pa...</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15744</th>\n",
       "      <td>uni cancel buat majlis konvo kata sbb kes maki...</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Dominant_Topic\n",
       "15740  malaysia sibuk tukar politik negara luar terus...            23.0\n",
       "15741                 makna isra miraj putus asa ada apa             1.0\n",
       "15742        prn bn mampu tahan rana amal politik matang             1.0\n",
       "15743  gak mungkin jago airlangga hartanto ahy cak pa...            15.0\n",
       "15744  uni cancel buat majlis konvo kata sbb kes maki...            29.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['Text', 'Dominant_Topic']\n",
    "df = df[col]\n",
    "df = df[pd.notnull(df['Text'])]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broadband-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Dominant_Topic'] = df['Dominant_Topic'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "substantial-headquarters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text              0\n",
       "Dominant_Topic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fourth-future",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0     3458\n",
       "32.0     749\n",
       "30.0     733\n",
       "3.0      717\n",
       "19.0     702\n",
       "26.0     641\n",
       "11.0     584\n",
       "29.0     565\n",
       "5.0      563\n",
       "24.0     546\n",
       "33.0     474\n",
       "20.0     469\n",
       "12.0     451\n",
       "13.0     439\n",
       "9.0      436\n",
       "22.0     410\n",
       "27.0     382\n",
       "31.0     359\n",
       "23.0     348\n",
       "16.0     344\n",
       "10.0     322\n",
       "1.0      304\n",
       "14.0     279\n",
       "34.0     229\n",
       "18.0     205\n",
       "15.0     184\n",
       "0.0      182\n",
       "2.0      143\n",
       "21.0     140\n",
       "6.0       93\n",
       "8.0       85\n",
       "7.0       84\n",
       "28.0      82\n",
       "17.0      41\n",
       "25.0       2\n",
       "Name: Dominant_Topic, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Dominant_Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "quick-medicaid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 12596\n",
      "Test size: 3149\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "train_size = int(len(df) * .8)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(df) - train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "interesting-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = df['Text'][:train_size]\n",
    "train_product = df['Dominant_Topic'][:train_size]\n",
    "\n",
    "test_text = df['Text'][train_size:]\n",
    "test_product = df['Dominant_Topic'][train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efficient-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "passive-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize.fit_on_texts(train_text) # only fit on train\n",
    "x_train = tokenize.texts_to_matrix(train_text)\n",
    "x_test = tokenize.texts_to_matrix(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hindu-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn utility to convert label strings to numbered index\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_product)\n",
    "y_train = encoder.transform(train_product)\n",
    "y_test = encoder.transform(test_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wrapped-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the labels to a one-hot representation\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aboriginal-concrete",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (12596, 10000)\n",
      "x_test shape: (3149, 10000)\n",
      "y_train shape: (12596, 35)\n",
      "y_test shape: (3149, 35)\n"
     ]
    }
   ],
   "source": [
    "# Inspect the dimenstions of our training and test data (this is helpful to debug)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "funny-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "interested-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-journalist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "vulnerable-fishing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "355/355 [==============================] - 10s 28ms/step - loss: 1.2527 - accuracy: 0.7365 - val_loss: 1.2539 - val_accuracy: 0.6873\n",
      "Epoch 2/5\n",
      "355/355 [==============================] - 10s 27ms/step - loss: 0.4188 - accuracy: 0.9126 - val_loss: 1.0445 - val_accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "355/355 [==============================] - 10s 27ms/step - loss: 0.1532 - accuracy: 0.9743 - val_loss: 0.9953 - val_accuracy: 0.7413\n",
      "Epoch 4/5\n",
      "355/355 [==============================] - 9s 26ms/step - loss: 0.0730 - accuracy: 0.9895 - val_loss: 1.0204 - val_accuracy: 0.7444\n",
      "Epoch 5/5\n",
      "355/355 [==============================] - 9s 26ms/step - loss: 0.0394 - accuracy: 0.9948 - val_loss: 1.0505 - val_accuracy: 0.7437\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "angry-admission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 1s 7ms/step - loss: 1.0561 - accuracy: 0.7396\n",
      "Test score: 1.0560972690582275\n",
      "Test accuracy: 0.739599883556366\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of our trained model\n",
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hairy-relay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "just tak masyarakat lebih parah politik kotor ...\n",
      "Actual label:30.0\n",
      "Predicted label: 30.0\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "sikap ikat alumni ilmu politik iisip soal wacana t ...\n",
      "Actual label:33.0\n",
      "Predicted label: 19.0\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "indonesia objek politik mau kacau barat lewat panj ...\n",
      "Actual label:15.0\n",
      "Predicted label: 15.0\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "so malaysians sekarang ni dah la huru hara pasal p ...\n",
      "Actual label:23.0\n",
      "Predicted label: 23.0\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "nu nu kata mau jauh diri politik omong nada ama po ...\n",
      "Actual label:33.0\n",
      "Predicted label: 3.0\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "bukan zaman angkat senjata peperangan cuma sekadar ...\n",
      "Actual label:5.0\n",
      "Predicted label: 5.0\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "malam usaha selamat ajar spm smk tengku ampu intan ...\n",
      "Actual label:27.0\n",
      "Predicted label: 27.0\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "usul tunda milu hendak negara gaduh nafsu politik  ...\n",
      "Actual label:19.0\n",
      "Predicted label: 19.0\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "aneh saran lebih baik tingkat kwalitas per nasi pa ...\n",
      "Actual label:28.0\n",
      "Predicted label: 11.0\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "politik kambing hitam siap lihat pro rakyat sangku ...\n",
      "Actual label:3.0\n",
      "Predicted label: 21.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here's how to generate a prediction on individual examples\n",
    "text_labels = encoder.classes_ \n",
    "\n",
    "for i in range(10):\n",
    "    prediction = model.predict(np.array([x_test[i]]))\n",
    "    predicted_label = text_labels[np.argmax(prediction)]\n",
    "    print(test_text.iloc[i][:50], \"...\")\n",
    "    print('Actual label:' + test_product.iloc[i])\n",
    "    print(\"Predicted label: \" + predicted_label + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "attended-reproduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               5120512   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 35)                17955     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 35)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,138,467\n",
      "Trainable params: 5,138,467\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "extra-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Model_Klasifikasi_Topik.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-rhythm",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
